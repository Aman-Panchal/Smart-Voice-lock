{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mfcc_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBem3AgXJlgb",
        "outputId": "09fd951a-6661-45e5-a3f6-9fed6439f4c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9tEl1RlKRWS"
      },
      "source": [
        "install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ-SwMsfJyAm"
      },
      "source": [
        "!pip install pydiogment\n",
        "!pip install -U pydiogment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-XQU6iXKdAS"
      },
      "source": [
        "### Let's read a sample audio using librosa\n",
        "import librosa\n",
        "audio_file_path='wav/aman/Recording (2)-converted.wav'\n",
        "librosa_audio_data,librosa_sample_rate=librosa.load(audio_file_path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "rmN7MAMuKicv",
        "outputId": "62519c4e-05c2-423d-dba5-0c4ce5055f67"
      },
      "source": [
        "### Lets plot the librosa audio data\n",
        "import matplotlib.pyplot as plt\n",
        "# Original audio with 1 channel \n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(librosa_audio_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4cfa571410>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAD4CAYAAAAq9brQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gU1foH8O9JJ9QAoZeE3iEQAkgvUlUQC6Aooliu+rPrxV4AQa8V9aooonhVREVR6dKkQ5BeEyBAaKEmIZB+fn/s7LK72U22zM7M7n4/z5OH3ZnZmUM2M/POKe8RUkoQEREREZHrQvQuABERERGRv2EQTURERETkJgbRRERERERuYhBNREREROQmBtFERERERG4K07sAnqhevbqMi4vTuxhEREREFMC2bt16TkoZ62idXwbRcXFxSE5O1rsYRERERBTAhBBHna1jdw4iIiIiIjcxiCYiIiIichODaCIiIiIiNzGIJiIiIiJyE4NoIiIiIiI3MYgmIiIiInITg2giIiIiIjcxiCaysunweaScyda7GERERGRwfjnZCpGvjJqxEQCQNm2YziUhIiIiI2NNNBERERGRmxhEExERERG5iUE0EREREZGbGEQTEREREbmJQTQRERERkZsYRBMRERERuYlBNBERERGRmxhEExERERG5SZUgWggxWAhxQAiRKoSY6GB9LyHEP0KIQiHErXbrioQQ25Wf39UoDxERERGRL3k9Y6EQIhTAJwCuB5AOYIsQ4ncp5V6rzY4BuAfAMw52cVVK2cHbchARERERaUWNab+TAKRKKQ8DgBBiDoDhACxBtJQyTVlXrMLxiIiIiIh0pUZ3jroAjlu9T1eWuSpKCJEshNgohBjhbCMhxAPKdslnz571tKxERERERF4zwsDChlLKRAB3APhACNHY0UZSyhlSykQpZWJsbKy2JSQiIiIisqJGEH0CQH2r9/WUZS6RUp5Q/j0MYBWABBXKRERERETkM2oE0VsANBVCxAshIgCMBuBSlg0hRIwQIlJ5XR1Ad1j1pSYiIiIiMiKvg2gpZSGARwEsAbAPwFwp5R4hxBtCiJsAQAjRWQiRDuA2AJ8LIfYoH28JIFkIsQPASgDT7LJ6EBEREREZjhrZOSClXAhgod2yV6xeb4Gpm4f959YDaKtGGYjUtPrgWZzJzMXtneuXvTEREREFHVWCaKJAM+6rzQDAIJqIiIgcMkJ2DiIiIiIiv8IgmqgM/xy7iLiJC3Dy0lW9i0JEREQGwSCaqAzfbTwGAFiXek7nkhAREZFRMIgmIiIiInITg2giIiIiIjcxiCYqg4S0vC4sKtaxJERERGQUDKIp6BUUFSNu4gK8s+RAqdttOnIBTV5chOS0CxqVjIiIiIyKQTQFvbxCU+3yrHVHSt1ubYppYOHGw+d9XiYiIn+zJe0CPl6RoncxiDTDyVaIFEVSOl7hZDEREV1z22cbAACP9muqc0mItMGaaCJFbkHp/Z1PZ+VqVBIiIuM7dv4KNjlomYubuACFRcXIzi3QoVRE2mEQTVSKE5euYt62EzbLhBA6lYaIyDh6/WclRs3Y6HDdEz9uR9vXlmpcIiJtMYgmKsUTc7bpXQQiIr/z585TNu9zC4pw9HyOTqUh8g0G0USlKCxmh2giIm89+v029P7PKqYJpYDCIJrITf9ZcgBn2D+aiMhlqw9mAABYL0GBhEE0kQfmbD6udxGIiAxh94lMp6ntLubkYwtz61OAYoo7IiIi8tgNH611um7MFxux/3S2hqXxnXOX83A6Mxdt6lbWuyhkEKyJJiIiIp8IlAAaAIZ8uKbUBwYKPgyiiYiIiMpwNjtP7yKQwTCIJvIAU0Ub2/ebjuHrMqZxJyIi8gb7RBOV4mp+kd5FIA+88OsuAMA93eN1LgkRWWMFBAUS1kQTlcJZfz7eB4iIglNBUTFyC1jBQqyJJiIiInJZ0xcXAQDSpg3TuSSkN9ZEE3mATZJERETBjUE0EREREZGbGEQTeUCwKpqIiCioqRJECyEGCyEOCCFShRATHazvJYT4RwhRKIS41W7dOCFEivIzTo3yEBERkfHM+ydd7yIQqcbrIFoIEQrgEwBDALQCMEYI0cpus2MA7gHwvd1nqwJ4FUAXAEkAXhVCxHhbJiIiIjKef/+yC/mFxXoXg0gVatREJwFIlVIellLmA5gDYLj1BlLKNCnlTgD2Z84gAMuklBeklBcBLAMwWIUyERERERH5jBpBdF0Ax63epyvLVP2sEOIBIUSyECL57NmzHhWUiIiI9DVnyzG9i0CkCr8ZWCilnCGlTJRSJsbGxupdHApyHFdIROSZV+bv4WywFBDUCKJPAKhv9b6esszXnyXSjeCchUREREFNjSB6C4CmQoh4IUQEgNEAfnfxs0sADBRCxCgDCgcqy4iIiIiIDMvrIFpKWQjgUZiC330A5kop9wgh3hBC3AQAQojOQoh0ALcB+FwIsUf57AUAk2AKxLcAeENZRmRo7M5BREQU3MLU2ImUciGAhXbLXrF6vQWmrhqOPvsVgK/UKAcREZGvLNt7BsVSYlDrWnoXhYgMwG8GFhIZzdzk48i8UqB3MYhII/fPTsaD327FhZx8vYtCGpu2aL/D5XtPZmF96jmNS0NGwSCayAMHz2TjuZ934qm52/UuChFprOOkZXoXwe/5W5e4z1Yfcrh86PQ1uOPLTRqXhoyCQTSRB7JzCwEAZy/n6VwSItLDR8tT9C4CEemMQTSRB5btPaN3EUhjUkrsTL+kdzFIBzl5hYibuMBm2bvLDupUGiIyCgbRREQu+HbjUdz08TqsPsgZU4PN0fNX9C6C4Xz4F2viiRhEE3nBz7r1kRf2n84GABy/wICKTE5lXtW7CLp5/6/gqYn/IIj+r+QeBtFEFDC+3ZCGqYv2+WTfUpr+fem33SgoKvbJMciYlu9z3H1rxCfrLK+LiyUysnO1KhJp6L+rHA8q/JutUkGPQTQFvT0nMvUuAqnk5fl78Pnqwz4/zp6TWT4/BhmHs/7PZ7KuDSz+YHkKkqYsD+ra6YAlHS+++6vN2paDDIdBNAW105m5GDVjo97FIAMrLpaY9OdeHD2f43D9rHVHLHli087lYND7fzOPcBBadSADAJCRxYw9gUY6i6Ip6KkyYyGRv8rK5WQpVLqUjMuYufZIieVL95zGhZx8vP7HXgDAhuf74dNVh3DgTDaW7jmN0UkNtC4q6UBKifjnF5a9IfktyRianGBNNJEXdqRnsvk2wDmqhRIAHvh2KybO22VZZt0/9tDZy1oUzXAKiooxddE+ZF4NnofTZi8tsnnPeMs1/jbZSlnWpnDWwmDEIJrIS3dytipdpWZc9mnGDOEgB0tqRskg+UxWniXg/mLNEZzJCr5BZn/sOInPVx/GtEX7UVBUjF3pgT/eoKCIYbMnHJ1XRuXKNzx2Ju8DwYhBNJGXzmWzD6SeBry3Gj3fXqnpMZ/+aYfD5dbNvsFUG2uWpfyfC4qKMWXBPtz48dqgrZWnwCHZn4OcYBBNQU2NuhBeXgObO83Op4Ow9tksNSMbryn9w6UEdilZbzjIkhxp9tIiFBdre/WcvSENd3lQY8xrPDnDgYVEFBBy8gr1LgLWBHG/yAOnbWuc/aexntw14ZtkVfZTWCwREaLdX8or8/d49DlWRJMzrImmoMZrY+C4w0d90z29xQdzEBlog8bI1l9OJp8hCjYMoonIb+UWFFle7zh+ySfHeOh/W32y30BmXXPHWjwiClQMoimoscLMv33xt+9nJzx01vEkK2UJ9trYQPn/v+9ktkIivZy8dBWFRcWW94VFxTbvSTsMoom8xZo23Vy1qok2mg+Xp2JskKY/tA6g/T2zwaerDuldhIAVKA9aWoibuADvLDmAs9l5uG7aCkxdtN+yrsmLi9Dv3dU6li54MYgmIr9l5PDsjx0nsTY1OAca+nncbIuBHhnExytTcfGKKdvNzLVHcCX/2mDqYz7MlU/OMYgmIiJVSSmxJe2iZsf7Y8dJ/HPMN8dzN4b295p38h+tXlmCKQv26l2MoMYUd0TktxivGNO8bScsr7X4iv7vh20AgLRpw1TfN7sc2LKu/STtvbv0gM37L9Yc0akkBLAmmojIp67mG7ffdqAxQh/0wx4ORPUXN0xfq9q++HziviV7nKcXzC0oQnZu8M2UqicG0UReys4rxIHT2XoXwy/sPZmlanO3NHSvaJOWryzWuwhBQ+0+6LkFRcgtcC/rgbMp4QPF4XOB/ZDgz/q9swptX1uqdzGCCoNoIhUM+uBv5BcWI7+QaYacWX3wLIZOX4OZa49gw6HzeheHNHL+srrTfh+/cAXnL+c5Xf/JylTVjrXnZJZq+yLyVJGL06OfzMwFYIzZW4OFKkG0EGKwEOKAECJVCDHRwfpIIcSPyvpNQog4ZXmcEOKqEGK78vOZGuUh0kOzlxah2UuL8Nrvnk0tG+iOnDVNCz15wT6M+WIjMrJyvd9pGfeW7T6agIVc9+Tc7art63RmLnq+vRJJby53us1/lhxwuo6MRbDDuUt+3HLcre1bv7rERyUhe14H0UKIUACfABgCoBWAMUKIVnab3QfgopSyCYD3Abxlte6QlLKD8vOQt+UhcocvruFfr09Tf6cBwP6GeUWFvsJl1c98tDzF62OQa5ydS2q2znSdagqeXa2Z89a+U6yJ9qVADKHjJi7Aq/N3q7rPzKvs52xUatREJwFIlVIellLmA5gDYLjdNsMBfKO8/hlAf8FHUKKgMjfZtjZFjTCorP7Vxu8xTUa1+0QmXvpN3WDI3528dFXvIviFbzYcVXV/jJaMS40Ud3UBWN8d0wF0cbaNlLJQCJEJoJqyLl4IsQ1AFoCXpJRrHB1ECPEAgAcAoEGDBioUm0g7RcUSWVcLEFM+Qu+i6CLtXE6J/qXMpxs8cguKEBUequo+2762BH2a10CbOpVU3a/Z6UwVuhsFkNyCIlw3bYXexdAcr1NUGr0HFp4C0EBKmQDgKQDfCyEcXhGllDOklIlSysTY2FhNC0nkrXeWHkDCpGW4mKPuICt/kV9Uskn/4hU2UQaL1QfPqr7P7NxC/LHjpM30x2pi6GQrz80sJYHC0bXLH/hq8iGypUYQfQJAfav39ZRlDrcRQoQBqAzgvJQyT0p5HgCklFsBHALQTIUyERnKkt2nAQBnS8kqEMgctUbe8ul6zFx7xKs8yqwk8g/8nshfGeFv15PeHCP/u171clBJagTRWwA0FULECyEiAIwG8LvdNr8DGKe8vhXACimlFELEKgMTIYRoBKApgMMqlInIMDKvFlhyqw58/28cv3BF5xJpz1mfvkl/7kXSm39pWxgiF7AZ3/9lZOUGxGRH7BNtXF4H0VLKQgCPAlgCYB+AuVLKPUKIN4QQNymbzQRQTQiRClO3DXMavF4AdgohtsM04PAhKeUFb8tEZCQv/rrL5n2qkuqNTLJzPc9pWlaY420gpGYg9e7SA9iZHrgp9y6U2lWJASlpL+nN5Rg1Y4PexaAApsbAQkgpFwJYaLfsFavXuQBuc/C5XwD8okYZiIxk69GL6NQwBkDJ9ETBWKlwyEdTIfu6slDN/X+0IhUfrUhF2rRh6u3UB85k5aJyufASAwG3Hr2IsBCB9vWrOPxcaZksWKlLetmZnqnZsc6okfteRVfzi1AuQt0BvWRL74GFRDrzTUh7y6frsWTPaYfrQoKwbe7Bb7eWuv6j5Sko9GAAjz9M++0PTmfmIm7iAny7IQ1d3lyOf/3v2ve1cn8G9p3Kwi2frsfwT9bpV0jSVTGfhMo09EOHycV0c7XA/7uy7D6RWeoMpXpjEE3kI79sTXe4PBiD6LK8u+wg/th5UvX9ejtJgVphQ66Bb2YZ2bmWSUzM+W1XHriWTWP811swxMvgQI/wa/ORC15N9MKQ0Va/d1epvs8iKVGs0cQ5nnLn2eG8j7IvHfNwHI1WkxL50g0frcXQ6cZ6OLHGIJpIYyFKDJ2RncsZ0ax4EvCUdYP755gx+iAPeG+13kVwqttU57l/Nx4+r8oxtK7EPHA6G7d/vgGTF+zV9sABKiev0CcpKZu+uAi3fKZNFgl/zfu96fB5/G/jMY8+u3zfmYCY7fBMFmuiiQxp0xF1ggRHzBXOJWohleW9317ldQ1fIDFia7FaAwvTLxp3pjdntVUr92dg9IyNqhxD62435pn1Zqs8c1ywylNx6nZ72zR60H17sWf5xD3txmJfw55yJtujgNabgegT5+1C+9eX4pv1acw24yMMoiloHTt/BS/+6rtpfQUE5m45ji1ptknvUzNMF8VA6K/m7+ZuOa75YKCcPM+zkfiadUej8V9vUW2/i3c7Hh/gK1m5+ta+HTyTjbiJC5CcFhjJpgKhA9qv2+2nr3DNrHVHPPrcQ/+zHQdy/ft/o/3rSz3al7de/X0P/th5yuG6nm+vwGu/79G4RIGDQTQFLS1utAt3l7xwvTKfFyxHtJ7B8Gx2Hp77ZSfuLSVYfMvD2qvSlHY8rUgpsfXoBaw6kOH2Z9elnsPfbs5A+KeTG7iv1KlSDgDQwUkmEVd4U3Fn/v0s3HUayWkXcN/XW/y6f+qXawNr+gZ3amVTMjyrCV6694zltSeDptV2xq47y5QFe/HbthM4fuEqvl6fpk+hAgCDaApavh7ft3jPaac34gnfJPv24H7Ik4DVmyZKczPt2Wzn/e2+WONZLVRpNh3Rv3byxy3HccunG3DPLPcD+ju/3IS7v9qM2z93L//ugp2nsP24Nk335j+L8FDbk/zEpauIm7gAqRnZmpQDAB7+7h8s359R6t+Z0X2y8pDeRVDVT04GfZtdzMnH+tRzAIzZzcxb7y87iC/WHMETP27Xuyh+j0E0BS2hQSOls+vvX/vOOFlTun7vrMJ9BqjJ9JW4iQvc2t6V+1u2kxYH87fvxxWEHtt/2nEQ6c6vYrObDwOPfP8PRmiUIs/8cGV/jt+rPDQMeO9vnx5/2iLTA6H1g/qXawKrNteX5m8/gV+3lR7oemPZ3tKvv3d9tQl3fLkJBUXFXvXmLyqWmLJgL04bIH/0lIX78MeOk/hyzWF8uDxF7+IEDAbRRD7kSk3pnM2uj7w+fC4Hy/e73wTvT9IvXlG11u6xH7Y5XmEJcLSPol+Z77u++HpYabC/SWff6GWr/uhSSrwyf7dljIKaCq2ezMyvvlyrfqtGoHp8znY8+eMOjz9fUFSMDYecDxovK4jefcKUNSknr9Cr1q77ZyfjizVH8OxPOy3L3vjD9YwxBUXFqvZX/r8ftmHygn0O12n1gBtoGERT0DJKuuaJ83aVvVEQ6fHWSnSe8pdL27pyfzt4xnGQZK6l1KO5Vu+sEc4CA0/TgC1y0Pffmb0nfZ/W0ZJVpJRz/IVfd2P2hqOlpB/0/g9j5tojhp4oIlC9s+QAxnzhfWaZi1cKvPorWKE8XBZY9Yn+at0RZLhYM718XwYKirS5QGnV1SrQMIimoKVFEK1mgGY9ixzTFXnP+vtfeSAjqHJ2u1JT646wUNdvJUOnr8FKDwY0esL+FLc+b+YmH9ekDNbdhe78Up2UgVS6z/9Wr+uMGtda+z30eWeVZscm32IQTUFLmz7Rrl0E7Udvr005h/l2KZkWWaUJW19KU6WRnLuchz7/WenRZ8uqwcvJK8SFK57NELbt2EWbyV3Gz/J+Vj5/ova92d3a1ke/+0fdAjhh/6AsrBbokS1jXap/nLdG8er83Rj75Sav9xM3cYFHf/MC6pwr9rW8V/KLXMoZrXVr6cu/7Ub6xZKzI64/dA4701lT7QiDaApaa1LcS9PlCVdvmvaZKcbO3ITH5zgfOX3iknEn77C2ePdppJ33bMraGz5aa3mdmnG5xIPGwPf/xgIXUqfZ1+YcO38FN/93vcN+ySlntMvaoCe1Jj/JySvEyP+uw5I97g2UzckvcruWzZPpob15UPZlHvd1qecMkfbMKJ796Vr/Z+vfyzcbjmKtkiVDDxLqBNGOHtic5YzOyMrFK/N323QB0cq3G4+ix1slKz3u+GITbvp4Hb7f5NnMiY5IKQOipp1BNAWtt5cc0LsIFu7WUBmkO3eZvLlEnlL656ady8GA91bjnaUHLevyC4tdfpCwvn9JKS35wc21Q/lWNytn/ad94fiFaw8XOXmF2H9au+4kat27pi7a5/HU6h0nLcMBJ1lCHJnhQXYL+4cFd27a3gxsK82GQ+dx55ebMH1Fqk/2749+2ppuyV6S9OZyh9s8P28nPlmp7e+sqLgYi/f4bqKguIkLSpwDr8zfg9kbjmLl/gwcPpfjs2OX5YfNx3DMrgLkhV/VG7/z6u97EP/8QtX2pxcG0RR0vt14FMv2nrFpztebs6ll/zl20eHyLf4yE5oK0VqGkqlj69Fr/+eJ83Y627yE01m5mPjLTmRk5SL++YWWQWfm7z87V58ZBP9OOYvJf+5F5tUCPPS/rRj8wRrN/ibVqv9Zsc/zvs0XrxRg0Aeup5o76EbAbWZdE71i/xmcdDJwcveJTLf37SnzgLfpy1NwNb8IP245hkyNJxoyoskL9qGoWOJCjuMuWj9sPo7/aFzxocW14ddttt32zF04cvIL8fZifSp64iYuwPPzdjnMBb825Rx+LiPPtiv0HlytFgbRFND2ncqySZeWnVuAl3/bjftnG2uyk/2nsy21ZNZTJI/873r8b2PJi83cZNuL2K70TLwyf3epNW0FRcU2tZ9a8DZYO385D68qKZ6kBA6dvYx9p7Kw1M3uA3O2HEf/d01ZGMyD57J0Cp7NXvx1N75cewTvLT1gybmsVT9dtWqinQWlvuBJkYultDyY3Pu183P+ho/WIiM7F1fzfdeFw5HH52zDv3/ZhWd+dlzrvXj3afyiQsDiL0a5MIHPvH/SPeraY8+Vc23WujSvj1MW+wdn8yBdX7WEuON0Vm6J3P1jZ27CMz9pUzZ/6O7BIJoC2pAP16D/u6ss74VR8to5EP/8Qjw+ZxsessrCAQAv/bYba1NK9gvMK7x2wx//9RbM3nAUl0qp0Zr05170fHulpim3Tlz0ru92p8l/WbJmJB+9iP7vrsaQD9d4lEUi28PME762/fgl5Ck3UrX6KpflBzdyk/taRrZrgfhqN6caB0yzQzZ7aZFL2yZNWY5bPl3v9jG8Ya51veRkgOxD/9uKp+0Cli/XHMbGw9oNUMz1Yd9we8lHHbe8WXtq7g58t8n7Wsyj5691lbiaX4SPlqeU6If8+46TXh+nLMVSYuWBDFxU/hbCQ4x7j9JanoFai51hEE0Bz1zjmFdYhDavLtG5NKWbv93xRXu6gxmm/rfxWiBUWFz6xSYjK9fSfLYzPdNhf+ITl66qfsPcfVK7ZnK1HDmXg9SMbM0ClR3p135HpzNz8c+xi5aa6Z3pl7BOx4FVWkiashzn7B7s/thxEpP+3IuiYomcvEJkXi1w2szvCldrLvdqnObQHLSFhbh+K568YN+1PNga2OZhn3c12deGvjx/DwqLipHjxYOxdUvURytS8O6yg6p0U3DX1+vTMH7WFoxXZqI1ft2r91ytYXbWzdFIwvQuAJEvXMzJLzGqW6++r2rY7KAP9JzNx3BnlwZo8fJiyzL7S05BUTEe+narzSyH5ot12rRh1z4nJbpPW4HrW9XEF3cnqlZuP7gG2pix5jB26DjpQL93r038sea5vrjpY9MsYtbfVSBKnPwX7uraEF0bVcOwdrXxf8oskxdy8vHrthO4qX0dr/a/YJfrk8Es3XMaA1vX8up4rjJPpHG1wJSt5Ep+EcpHmm7L1oHG7A1pCBECN7bz7vfgCTUmLfGFodPX4OCZyx6fGyM+WYfUKUMQFhqCK0o3nisad+extv34Jcxce6REH2kjW5tyDnHVo1FULNGwWnlkXinA2JmbMH1MAuKrlwdguheXiwhFVHgoAFPa08TJrk2mpUMWSrcxiKaAdP/s5BJNg1ku5OX0JykZl0vUnG09ehHXt6oJAPhmfRqEgNNpwouLJUKUpkNz/8Ble89gxt+HMKFHI8s6e8cvXEHl6HBUigovs4z+FkTrGUDbO+phakB/9e3Go/h241E0qdHLsswcUOzwMketfc710hz3sguSO8zn7/bjlyyZCu7tHo9h7WrbdC15Zb5pXMBLv5VMy7jnZCZ2n8jEqM4NNCixcZgz6TwwOxmZVwswvnscBrepbcny4YomLy5C2rRhlsF8UkqbAcxam+lBBhq92LcO1K1SDrcl1sOuE5n4ZGUq3rmtPQAgYdIym+1GJtQtsa+cvEKEhghLoJ2TV4hRMzbgjqSGPiq9ehhEe2DlgQyECIHezWL1Lgo5ccRBaiDzCRpIRv7Xtg/n/bOTsfzp3thzMssyIM+ZRi8sxKLHe6JxbAXcaJWT+c2F+xFfvYIlGH9izjYs2n0aeYXFGJNUHz9sPo56MeWw9t/9yiyfVn18A1F+kW2t2JdrDqND/SpIjKvq8T4zrxbgpMFzjDvK2OHtA8VfbmQROX7hSokAQUtfrTvi1vbDppvOXXMQvfJABhpWjUaj2Aqql82Ilu41DTLedOQC0qYNw+QF+9z6/C9b05F11dRKufnIBbc/ryYtB+qq7cSlq/jgL1O3w5+3pmNEh7ro0bR6ie3m2dW0X8jJR8dJyxBXLRqrnu0LAHjw263YfSLLJqXe5bxCVIg0XsjKPtFuysotwPhZWzDuq8147fc9NhfbtSnncNBPJms4fzkPX687YojRrxdz8lUZbW1WUFSM83b9JzOvFuC6aStUO4aRfbnmMB5TmsPLMuTDNVi0+xQO2P3d3j87GSv2n8HuE5n4bftJywCPHzabpkpOv3jVJpNBaka25pkNAt2Rc7aB4+QF+3DrZ2VnLwCAhbtOYfvxS5i+PMVm8ooxMzYG1cyMntBy0J4zrox/LigqRnbutdY1c7/y8bO22HQL8oYefYS94cnDz9M/7cAv/5j+n+aAnLw3duYmhxNa2euo1FSnnb+CjKxcvLV4v8MJdtq8usQQ8Yo9YcRClSUxMVEmJ+uTouzLNYdLPKl2bFAFzw1uYRns0bNpdXx7X5cSnz2dmYv0i1dsapIOnsnGmaxc9GyqTq12Tl4hUjIuo0P9KqVud/dXm/H3wbNY8FgPtK5TuWgi1icAACAASURBVMT6Q2cvo1H18thzMgsXcvLRy4Na99yCIlzOK0T1CpEO1x85l4PDZy/jvm9M3+XX4zujT/Mabh/HrLhYYtORC6hWIQID37etzWpaowJSMrSbSCNYJMVVtfTX7tM8Fq/c0AqNYivg01WH8Nbi/ahdOcoyaQp5bv+kwZa+7w/3aYy1qecwc1xnxFaMRFGxRLGUCA8NwYWcfJy/nIfrrf7+y0eEYsUzfbAzPdNwqR3JscSGMS5lqrD3aN8m+NhqQpJDbw5FqNIt67dtJ/DO0gOYcnNbvDBvF4a1q40JPeJRo1KU0/3pWSNPZG/ug92QFO95S5ynhBBbpZQOBwsxiHbTJytTXUr4XqNiJDa/OMCStqZ8ZJgl1dLWlwZg6qL9eOXGVmj3mmnqz9IGRzz38w40qVEBoxIboP97q/D5XYloVbsSQkKAyLBQ/JR8HBnZeXikbxObi1658FA8O6g5WtSuiJOXclGnShRqVIxEkxoVcdPHa7EzPRPzH+mOh7/7BycuXbWUYeWBDIyftQVTR7bF8/NMzSlJ8VXxw/1dERoisO9UFlbsz0DXRtUQHRGKlrUrOSz3HV9sxPpD5x3+33ILimwGxJktfKwnxs7chAs5+RjSphY+vqMjQkMELucVorCoGJFhoSgXca1bRkFRMbYfv4QjZ3OwNvUcft9xEjcn1PWrwRlEnrixfR18NCYBd3650e0ZLyk4VCsfgYbVojG0bW1L5U9MdDguWqXCTJs2DLkFRSgslqgQGYar+UVYvOeUIfIUE1n79r4k1Soc3cEgWkWOaqLV8MkdHdG7eaxNnx/7WoAnBjTFB3+lIDIsxNK8/tnYTiXyCpdl1j2dLRka7D3YqxE+/9v54IaPxiRYRs6btahVEbPvTULq2cuoUi4CV/ILkRhX1VL+9RP7oWalKKRkZOPC5XyEhYYgPFTg5v+WnZO1e5Nq2JJ20SYh/YejO+DxOdvRvUk1Bg8U1F4c2hJTFurXh5P837/6NManqw7pXQyiMv3vvi4O+1n7GoNoFX27IQ0vzy99wJY33h/VHu8sOegwjy8RERFRMDJiEK3KwEIhxGAhxAEhRKoQYqKD9ZFCiB+V9ZuEEHFW655Xlh8QQgxSozy+5OsZ7578cQcDaCIiIiKD8zqIFkKEAvgEwBAArQCMEUK0stvsPgAXpZRNALwP4C3ls60AjAbQGsBgAP9V9mdYoZySk4iIiEhTBWXMzKsHNWqikwCkSikPSynzAcwBMNxum+EAvlFe/wygvzBV6Q4HMEdKmSelPAIgVdmf4bz82260fW1Jmbl3iYiIiEhd42c5HsulJzUyV9cFcNzqfToA+/xulm2klIVCiEwA1ZTlG+0+W3I6GwBCiAcAPAAADRpoPzNT5/iqCA0RKCqW+HbjUc2PT0RERETGYbzpX5yQUs4AMAMwDSzU+vg3ta+Dm9rXAQAG0UREREQa+ufl6/UuQglqdOc4AaC+1ft6yjKH2wghwgBUBnDexc8aTpu6przIn9zREc8MbFbqto1jy2tRJCIiIqKAZcQhaWrURG8B0FQIEQ9TADwawB122/wOYByADQBuBbBCSimFEL8D+F4I8R6AOgCaAtisQpl86pd/XYfCIonySk7nR/s1tax75Pt/sGDnKbx5c1uMSaqPr9en4fU/9upVVCIiIiK/F2LAKNrrmmgpZSGARwEsAbAPwFwp5R4hxBtCiJuUzWYCqCaESAXwFICJymf3AJgLYC+AxQAekVIWeVsmX4sMC7UE0Pamj07A/kmDcUeXBhBCICzU9lccHRGKpU/2wogOdfDrw9chbdowLHmiF+pWKYf29UpOvz24dS28flNrAEC/FjWQMmVIqWW7rVM9j/5Pn9/VyaPPlaaW1XSyres4ntXQkU4NY1CnsvOpaEtTt0o5jz5H6lo3sR/2TxqMN4a31rsoQalJjQqW14kNY3QsCRnVkalDsX/SYGx9aYDD9esm9tO4RESliwhVJSuzqjjZio8dv3AFPd9eiW/uTUKzmhVQu7LzIO+z1YcwbdF+AMBT1zfD9a1qWqbULiwqRogQCAkR+HhFCo5duIK5yel47cZWOJ2Vh8SGMZgwOxkrnu6Nfu+uBgDseX0QWr+6pNTyVYoKw9/P9UWV6AhczMlHwqRllnVPXd8M7y07iJ5Nq6NN3cqWWa3Spg2zzEZYp3IU7u0Rjwk9G1mW/fKvbmhdpzKiwkPx89Z0PPPTDoxMqIuKUWH4ZsNRDGhZA+sPnUe9mHIYkVAXP245jjuSGuDB3o1tymY/YyNgmsZ2/qPdcSYrDzUrRaLHWytRLjwUH4zugA//SsHX4zvjSn4R+ryzqtT/N5Xu2UHNXZre3pEPRnXAiATT+OBDZy+jv/L3SOrb8uIAdJ7yFwCgY4Mq+OfYJbx6YyuM7x6PjOxc7D6RiX4tamLlgQxDjmwn37k5oS7eu7094p9fWGLdh6M7YHiHa2P4d6ZfQvnIMIQIgVAh0KBaNADfTy5G5Kph7Wrjkzs66nLs0iZb8ZuBhf6qftVopE0b5tK2TZXao+ljEiyDGM2sa7TN3UeeGdgcsRUjLRPAmI/z0ZgELNlzGuUjw7D3jUE4eekqdqZn4qm5O0occ/qYBFSJjgAAVIkOtyy/pWM9PNa/KR7rf62ryqerDuGGdrUt74UA1j/f3/J+0wum1zWtaqC7NqoKALizawN0algVrw9vU6IMD/dp4vD3cWTqUOw5mYUmNSpg+vIU/HfVIWxVBhbUizFd5D8Y1QFdG1VDrcpRGNS6lsP9kHs+G9sJA1rWKDOI/mhMAp6aux0FRdcexH96qJtNzafxGt/807C2tbFg1ykAwNSRbfH8vF0AgNiKkWhbtzJ2ncjEjLsTUb1CpOUzNSpGoV8L07nYt3kNy/JRifXxY7J1QiUKNC1qVcTUkW0t94YmNSrgq3GdEVsxEuUiSk7F0K5eFYf7uatbHINoMoRmNSrqXQSHWBNtMKkZl22aYtVyNb8ILV9ZjMf7N4UEMH15Ch7t2wTPDGpus92V/EJEhoU6nFQm82oBoiNCER4agiv5hQgRAlHhxpwbx1EtdrDY9EJ/XMkvQl8Pa+PND2MPfpuMJXvOWJanTBmCV+bvwQ+bj1m2GzZ9DfaczCrxWbPDZy9bWkbIc+bf6+W8QlSIDMPWoxdx6Oxl3J5YHwVFxTh56SoaVit9EPOczccwcd4u3J5YD3OT07UotlsGt66FxXtOo0Wtith/Ottm3Ws3tsJrQTS25ODkIWj20iKH6+7rEY+Za48AAJ4b3BxvL7Z92B3YqiYmj2iDGkplxslLV1ExKgwVo8JL7MsVRr+Wtq9XGTvSM/UuBrnghaEt8OOW4zh0NqfMbUcm1MXbt7ZDkxdN54GjeEUrPp/2m9TjiwAaAMpFhCJ1yhA8MaApBraqCQDo37JGie2iI8KczspYuVw4wpUa8eiIMMMG0ADQvv61mhXr2vNgULNSFOKru58V5j+3trMJgj8YlYDx3eMs78NDQzB1ZFubz8wc1xmv39QaNyfUxdPXl8xUY64JI3VUUMZidGoYg9sTTYmNwkNDygygAaC2Ml7AlW31EFM+AmnThqF389gS6+I8+Hv2ZxFh127NfzzaAwAw+94kLH6iJ16+oRVm3dMZ9/WIt2nF2z9pMFKmDMGMuxMtATQA1KlSzuMAGrAd22JE85XfjyfeuqVt2RuR26bc3KbE+KymNSrggV6NHd4TYitGllj23qgONi3wBUXGm60QYBAdVMJCQyCEQJu6lZE2bRgSGgTugKP5j3TH27e0AwBEhYcibdqwoBh0+Ghfx11jHDkwebClu40j5SJC8eqNJQcG/v5od0wfkwAAqFU5CuOui8P7ozrg/6y6/pD3zOkxZ93TWZX99W4Wi+8mdMFDvRujnYNBzEZxV9eGaFA1GtFW3Q56N4vF0LbadNfqpPFAzDkPdMV/77zW19P6QfZffRqjbT3T9bpXs1i0qGUaI9O3RQ28fEMrm/1EhYdaKjnUZITnYEdBlrVdrw1EypQhSIqvisf6uX4N7NnU9oEtbdowl7tf+oInlR96++LukhW0N7Wvg7duaYdFj/e0LFv2VG+n+1j7775lHsd+zJRRMIimwKVc/M09lpY82Uu/snjhwd6N8MGoDg7XWdcUTxvZFv/Xv+QN5PCbQ7H9leux6PGeeO/29gCAejHlEBkWijkPdMPtiaYaA2ctEIBtf/l29aqU6LPvD+yDDmfCQ/WPGh7p2xjLn+6DtGnD0LdFyRYjT3VvUh2hIQKz701SbZ9quSPJNBNtvZho/P1cXzxn1XQrhMB7tzs+B7z1SN/G2PC8KRPFZ2M7IkzjNFpt6lbG0LYlW8vSpg3Dvwe3KPPz00a2xQ/3d/VF0QCUfl3whYoOMl9NdPB7mDW+M/56ynRNrxhlaiWd+2A3PDGg9LkbrEWGOQ6BXhza0uV9qKmpj1qifeXlG1rh+lY1LUFw+YhQrH62DypGhSMkRFgSI1iz/2sa3LoWIsNC0SXeVKGz8LGe2Pxi/xKfq1o+QvXyq4EDCylghShVKBKmKLpCZBh6Nq2ONSnn9CyWW2Kiw/F//Zpil4M+f9ERoRjQsiZmrUvDxCEtMFoJQszGJDVA72axCAkRqBIdgSrREWhWsyLWpJzDfT3iLds9P6QloiPCcEM7x4Hxmuf6omKUZ5cKbwPSI1OHQgihSr/M+3rEY9KfZferHdS6Fv7ceQpf3p2ICbO1HXtxa6d6eP2m1k5TaKrFFzWW3nh2UHO0tasdt78Bh/ioSrSwWKJ25XKWGsg2dSvji78PY9vxS9jp4762k0e0sXTR2fB8P2ReLXB7H/bnvdo+uaMjhn+yzqfHsBYfW97yexfCVAlSwe76E1+9vM1gWWvu5BKuEh2BPs1jcV+PeLSte+3vz5yd5PpWNbFs7xlnH1ddr2axWKrh8Tzx11O9cfFKPm77bAN6N6sO4Fo3s/CwsruWjexYD28t3m9536ym6cHhm3uTcOlKAWp5mN5WL8a6khKpyHwptR47W87A/bjNeje71sT4x//1sFyg7EWFh6J7k+o4MnUoHnLQ1DV1ZFsMbmPbBB4aIvD+qA5oY3XDiCkfgdduam3TD9Na/arRlgwu7qoXE40HejXy6LPAtT7VK57ujdXP9sHDfdRp0lvxdG+bBwmzXs1i8Z9b2+PHB7pigDJ2wNdaWQWL79zW3ucBNACn37WRdGlUDfMf6W6plfJVDXFxse3g+nox0Xh9eBvVamAd5f83G9u1oeV17crlLN01jKRB1WhNj/e+VatblXKmFjD7BAjdm1RT5VihIQJfj09Cz6axNtc4vfIt2P+ujVj7Gh0Ris5xVZE2bRiaKBkzzNesZ10Y+PdQ70bYP2mw5f11TUyBeFR4qN8F0ABroimAVVIuwNWsLkTma2O18hHIvFqAwmJjZKf5aEwCusRXRXZeIepULof9p7NwJivXksrPUSXcnAe6Kuv0735Qmru6NsSMvw+7/bkWta6lNGoUa6qteG5wCzw3uIXXNdONYis47RdcLiIUXRqpc5Muy/jucXj1xtaaZ0DQustCWZz9CVsPEPbVbGXO0rupUfNt3b/W6FkujCB1yhCEhYagZe1K2Hcqy/IdmC/TA1vVxMs3tHI72NqmpEY1z4PQKLY8po9OcLp9Q6Umukt8VXSoX8XjnPnuGNGhDrraXXdWPt0HCZOWQu/b1KDWNbHt2CVkZOc5PFfDQ0Oc9iVf++++KLRKgyrssnrZ/5/9jfGrI4g8NKBlDbx1S1ubtDjmPsSLn+jlcRcFX6hWIQI1KkWhcWwFlIsIRUKDGAxuc62fZLGDqpFmNY2ZN9OeEadqBWAz2YRZ5XK2WQxKq0VUQ+c4Uz/AER3qaJpFRu0HL3dmJHVEaJBR/NM7O2K9g1n4bnTSv1/tEs0c5zBDluFp0TJiZs7GUF4ZVGq+dhRLiW0vX4+P7+iI+lWjy+yOZP+7jikfgRirypRZ93S2aY2z17J2Jax5ri/u6xFvUwnjC42ql8fSJ3vhg9EJJVqIQkKg+fwHTw5ohv4tauDLuxPRQXmIfe/2Dvjm3iSM7doANSu69wBTLyY6oLPrGCeKIFKZEAKjOtv2F7yucXXLE3NoiHGeIa9rXL3U9cV22X2ecpBOzqhCPQzYHD04mDWvWREHzmQ7XW/PeuBVaSPgJ9tPBuTDWv5KUWGWAWUflFIr5iuP9m2Cj1emqrKv7yd0Rfs3lnr8eV83pix9spflodN8/i/fd8bS0qNFmfq3rIllT/bC4XM5+G7TMZtBwUYWERaCB3s3wuer3W9N8tStneoh+ehFxFcvj7PZeZASNkFwWfq3rImVz/RxmivflYe2+lWdtwKq6YWhLW0qRKwnUwrT4R71aL8mlq5MvZvHoqhYIio8FC1rV8LkEeqlBOzepBrWpZ5XbX96YRBNQUuLsVUNq0Xj6PkrXu+nXf3KqBgVhuzcQgCwmUnS6MpHetYP/bZO9Z2uW/BYD0sSfld0a2xqMpz38HVo6KSP5zf3JqFytG1NdHUf1kJNGlFy9k4tPXl9M1WC6Ak94kv83lzVp3ksVh04i9o+7gvpqNWmf8vS+7z7ona8ac2KaFqzot/NrtpJg3So1lM6j05qgNFJDfDo9/8AKP2B2hm1/qZ83V0urrrt9WhMUgPc2L4ODmVcdji7pK9ZNxyGh4bAV8OIvpvgu4wyWmIQTUFLi6f8tnUrlxlE392tYanrAaBSVDh2vTbIL/tVVowKd2uWvKVP9kLj2AoorRdIWGiIRzOVdbQLBhIbxiD56EWsfKaPwxrqEQl1sXx/hlvHKMtPD3WzdOPQU2iIwJwHumL0jI0e78PbnLpjuzTEuOvi0KdZyQlWdOdl7FTJQN3FvDVQg6B/mIPuTDWUrgPOBleXprTJwNyJi9XoGx9fvTyOnLOdpW/WPZ1RLiLUMjjPWoXIMMt4AK2HvBh9jI3RGKc9m0hjWrSUOatAsZ745fWbSk5oEmhc7RMXEx2O+OrlERoiyryYz3+0B261mxXLXT891A173xjktIuHL9KqGSGANtM6C0FcNdtat5AQoG/zGoa8cXtbIiP+n7yhdb5owDSt+Vu3tEU/FXOlu0uN//XKZ/rYvO/YoAr6tqhhuEF1y/x0LgU9MYimoKVFTbSE4yhlZMdrg9rcudl+P6ELJg4pewIGo3GlabxFrYrY9spAt3IY2w8EdGTLiwOcl0sIREc4r+VSKw7a+8YgdXakMmd/n76y6tm++Pmhbpb3Wgwo9JS3370/jVswqqjwUIzq3ED1BxJ3dqfWofu3qIERHergzi4N8NldnVw/vobnSFM/GaxuJIHT3kTkpkYOmtjU1rd5DSzcdbrE8icHNMNHK9zvj3pdk+qWvJr+xJUbkSe1vuZE/aUpa8pgLZQWqOupc1xV3JxQFw2qRuPD5Sk+PZY5H3ZiXFVLX2hf+np8Z9wza4vHn/c2eBl3XZxXnzca+1zN/uDP/+vhdWuLWkH0zHs6q7Mjla18pg+W7ztjyJzU/oA10RS0bu/sfOCaWsz5je0ZNe2bnjwZROPrWpqcvEKf7l9v4aEheH9UB0teXF/6l9VEOeWVh4owN2e0vL9nyQlynOnjZEY7VwVYb4yg1KZu5RIzYQLutf75aqZMl/n48PHVy2NCz0YY2dG7rnHBypjVI0QaGNS6Fh7r1wTTPagRdl3JahB/mDVRba7cB6I9GYnu4xtMaSnQ3DVtZFtdRtu7wtdxwrhuDW3yMU8e0QYta1dE9zJSO9p7YWhLfLHmiNrFc8ibmjnrMQ+B4t+DW2Dqov1lb0gAgDXP9cXqg2dRwwAtYc78ZNW1ijzDIJqCWoNqvk0C76gpsXkt9jvzF6XllHbVkidMg3VGJzUoY0v9RYSFIL+wuOwN3WRf8xdTPgKP9nM/TaO7fWM/vbNjqVkaSuPNw+7vj3b3+LNG9WDvxgETRLvzV+TpVOz1q0bbTOvuKTWfb+/s0gD9WtTA2ew8VIgKM9QgZ3/FIJqCmq8b6koLmCePaIM6VXybH9coXIl9IjxI3O3r70+NgXf+8NBk5AF+3hjS1vNZIL1pxq9Wwbi1j+Rey4s/nL+umnKzepOlkAmDaCIV1agYiYzsPADA3Ae7oWJUyewRSfGmp381ain8hStB2tSRvMDrLTBDac/o3RXWiJrWqICUjMt6F4PIMBhEU1BT+0ZpnUvV2Wj25wY1V/egfqCs33OlqDDUqOR+rbyvc/H6YUICj5h/jc1qVsSuE+5NYGNE8x6+zut9MIguackTvSABNH5hod5F8YovW16GtKmFwmL1LhxqXOPmPXwd/jl6UYXSkD1m5yBSkaMmYOvBG4/3b4owLeYbDxK+784RXOKrl8fHdyQAKHtw3KYX+mtRpBLeva19mdvYz0zpGUbR9kJChC6TrqjNlw9In47thC/uTvTdAVyU2NB0DozoUAcdG8RgQs9GOpcoMPFuTkFN7Yup9fwt5gDMevDGk0E6AcNtib5JJ2j02sKeTf0rp7fEtSwpZf1ua3rQcqAG64mKfMkf8yL7qz2vazsZka8uG9/el6T6Pj0t68//ug5p04bhg9EJqpaHbDGIpqCmdrOes8FIvz58HWaO0792Qi+Vy4XbBJTWaZ8iw0Lw0g2tfHLcjc97V1sa7mYeY2vPDW6Ob+/r4tXxtdKtcTUIAYzvHoceTWIxKrE+3lRxEJKaDztaTaddu3LgpakzqvKRgdGzNEGVFhD3JSkVNYNa19Tl+MGMQTQFNbXvx+O6xVleW1dkJTSIQf+WvMABQOe4GCx7qjfu7mYaWHlg8hDc7qOa6lqVvastrVHR88/7U0VmjYpRODJ1GDo2iEFEWAjeurWd1787azHR2s2G1t7B5BqeeKRvY7Stq86+As1oDSaq8imDt2BZu7dH2RMMzX2oG9KmDcMnd3TUoERkzasgWghRVQixTAiRovzr8DFMCDFO2SZFCDHOavkqIcQBIcR25ce7KaaIdHZvj3h0iWfuTUfMffI+G9sJlcuF443hbZA2bZhX+9SiUrKdh0FZsKQvLEv1CpF4qHfjsjd0wy//ujZw0LqP7oqne+O7+7uqcoyw0BAMblNLlX0FGmbS0U6H+lXQpIbjmW/thYWGoF5MOYzyUaUEleRtTfREAMullE0BLFfe2xBCVAXwKoAuAJIAvGoXbN8ppeyg/GR4WR4iw1Ajx3Ag6d0sFmnThqmaQ1edAWS+MaKDNn13fSUyzHR76FC/ilf7Gdu1ASLC1G30TLAqk3Xf5UaxFVBBxa4BRu9zrxetutT4irvd+FY+08c3BXHRqzc67+42Jsk2YF77735469Z2vi4SKby9sg0H8I3y+hsAIxxsMwjAMinlBSnlRQDLAAz28rhEhmW5vzCG9rmG1cojbdowpE0b5tU0zaXxJFyoX7Wc3wcaDauVxwejOuDD0R30LkoJQgC3J9bz+XG8mXAl0FVX4WH4l3910yXLi7tfq6szl/rqryXWagxJt0bVLK9nje+MV29s7aOjkiu8DaJrSilPKa9PA3DU6bMugONW79OVZWazlK4cL4tS7jpCiAeEEMlCiOSzZ896WWwiEzUDnaFt7Zp+ef8NDB78jXw1rrMPCqK9EQl1UcVBf+ZIN2qWfZGTVwhhM/Bx8RM98dsj6k+17Ulf/WcGBkcGngWP9fB6H50aVtUly0t4iG+Gg/mq3sQ8yHXyiDb44YFr3ZX6Nq/h8bT2pI4y272EEH8BcNQx7EXrN1JKKYRw92/oTinlCSFERQC/ALgLwGxHG0opZwCYAQCJiYms4yNVqHl799XgOHJN/arRuJCTr/p+3fkbWfNcX0SGh3g1INHofn34OoeZK9rVq4yd6dpN1GJ+AJYAWtSq5JNjVC0fgRva1cafO0+VvbEiMiw4ghq9UhyqoXJ0yZlkjaxyuXCvx4+Qb5T5OCalHCClbOPgZz6AM0KI2gCg/OuoT/MJANbRRT1lGaSU5n+zAXwPU59pIs2oVRH93ODm6NPcNC7W3OeXNQTa+spHKQRdrXVNmTIE9atGB14AbVVl0atZLBIaxDjM3PHdhC7o2MC7/tPusPSa8nGVyus3uddczh4ggWlkgn+PcSDf8LZN43cA5mwb4wDMd7DNEgADhRAxyoDCgQCWCCHChBDVAUAIEQ7gBgC7vSwPke6mjmyLN29uazP4iXxPzQGL1lxtYQgPgpkoZ9zVyem6ilHhDrMI+CqoNO+3nI8fVn31d0XaS/DiIe+9UcYbGxAMrm9VE1NubqN3MZzydhjzNABzhRD3ATgK4HYAEEIkAnhISjlBSnlBCDEJwBblM28oy8rDFEyHAwgF8BeAL7wsD5FbfNFfs1JUOO7o0kD1/ZI+wlyYcKV9EDwwVYoKM1TrihACLwxtYWkBIirLrw+r32/eGhsh1GeEKdRL41UQLaU8D6DE0FopZTKACVbvvwLwld02OQCcV2sQaYBNr6SGeVZ5iwNNpXJhGJNUH6M6l/1g2KtZLOYmp2tQKpMHeqmbf5rIHwxsVRPD/TyFZqAI/PZHIgoas+/VZ1iF9YQfgUYIgakj27mUL/qGdnUwsBVn5qSy/fRQN72L4Ldm3J2IYe1q610MAoNoCnKBG/oEp17KhC5qSlJmoJw4pIWq+w1U5e0mO+E5RvZ6N4tFYkPjTpRE5Cr1pnYiIgpAtSuXQ9q0Ydh9Qrv0bf6sXkzJ9HdE1r66p7PfT0ZEBLAmmojIJa3r+CYXcaB5rH9TNI69NsNbsMVKDA7LFqjdn/jVBx8G0RTUeNEjVwkhEB1hnOwURhUeGoIBAdYveurItmVvREEvUB8OyDl256Agx4seee6zsR1RLyZa72KQj/EqoZ7H+jXRuwg+sfTJXkEzWyVdwyCaiALO38/2Rdr5HJ8fZ3AbjpAPBs5arJY/3Rv9312tbWH8XP+WgdVKYdY4tuREQxT42J2DyA0Nq0Vj7b/7lljukKG5RgAAC4xJREFUi0lbyHMNqkWjV7NYvYtBCIw+wtWdzFpYNTpC45KQnno1i0WDqtF4rH9TPNzHNke5//+VkydYE01Bzd37+4Qe8agXE41h7Wpjwc5TvikUGdZDvRvjvWUHAQCLn+ipc2lIK/1auD4rIoOp0vnzM5V9Hvq7u8Wh69TlOpWGjIA10RTUPL2e239OQnpbFPIDj/VvanndohazdQQLd2rTW9Su6MOSkJHUqhyldxFIZ6yJJiIi8lJiwxhMH5OAOlWYJzsY+XMNO3mOQTQFtUDor0na+vmhbth+/JLexSADYgBdNo4foUDCIJoIQLXyETifk+/x53ljCB6JcVWRGFdV72KQjpLiq6JLPP8G6BpWyAQn9ommoBZf3TSzmnVfVyLyTqxVNotAjC3mPtgNTw9sbrMsEP+fvlAhinV3FDgYRFNQa1KjApJfGoC7uzV07QPKnZK1DkTOje8ejzoBNujqj0d76F0Ev1Qu/NoEJC8ObWmpuCAKBAyiKehVrxDpdVDM7BxE14SGCNzYoQ6AwOnq1LZe5VLXD2pdS6OS+Bfra+PA1oE50QoFLwbRRESkuqY1TKne4qsH7rTolcuF47rG1fDZ2I64r0e83sXRXM+m1cvcJizEFGa8Mbw1GlYLvFrot29ph7ocUBq02DmJSAWBUttGpJZbOtZFs5oV0K5eFb2L4jMhIQLf399V72Lo5ou7E5F5tQDdpi5HsYPGuP/r1wQLdp7C5bxCdG9SdsDtj27vXB+3d66vdzFIJ6yJJiIi1QkhAjqAJiAqPBQ1K0U57cw2vns86lU1tUREhjHcoMDDv2oixZA2rvdpZL0zEZFzs8Z3RtXyEfhoTAI+G9sJ9WICt1sPBS8G0USKT8d28vizsRUjy96IiChItK1rGohZuVw4BrtRQUHkTxhEE3mpXb3KuKVjXb2LQUQ+Zg4MqXRPDmiG6hVYsUCBjwMLibw0sFVN5o0mCgLzHr4ORY5G0JGN+3oGX6YSCk6siSby0kDmhyUKCuGhIYiymjyETKTyXFGOvxsKMgyiidzQu2mszfsPRnVAs5oVdSoNEZFx1Isx5UsOYcMcBQl25yBy0epn+6BBNdMIc/beICKy9b8JXZCcdhHREQwtKDh4VRMthKgqhFgmhEhR/o1xst1iIcQlIcSfdsvjhRCbhBCpQogfhRAR3pSHyFfuuS7OZrYt8wxVVaLD9SoSEZGh1KgYiWHtautdDCLNeNudYyKA5VLKpgCWK+8d+Q+AuxwsfwvA+1LKJgAuArjPy/IQ+USlKNualScGNMNnYzuhd7NYJ58gIgoOr9zQSu8iEOnC2yB6OIBvlNffABjhaCMp5XIA2dbLhCmdQT8AP5f1eSKthLrYmS8iLASD29RiVg4iCnr39ohH2rRhvB5S0PE2iK4ppTylvD4NoKYbn60G4JKUslB5nw7AabJdIcQDQohkIUTy2bNnPSstkYeY1IqIiIisldn7XwjxFwBHObxetH4jpZRCCJ/FGlLKGQBmAEBiYiJjGvIJZ/Uokn9xREREZKXMIFpKOcDZOiHEGSFEbSnlKSFEbQAZbhz7PIAqQogwpTa6HoATbnyeiIiIiEgX3nbn+B3AOOX1OADzXf2glFICWAngVk8+T+QLtyXWd7jcnP+UiIiICPA+iJ4G4HohRAqAAcp7CCEShRBfmjcSQqwB8BOA/kKIdCHEIGXVvwE8JYRIhamP9Ewvy0Pklckj2ti879GkOr6b0AWjOjsOromIiCg4eZURXUp5HkB/B8uTAUywet/TyecPA0jypgxEarLPzjGyY110b1Jdp9IQERGRUXHabyIiIiIiNzGIJnLi5oS6GNqWs28RERFRSZzgnsiJ90d10LsIREREZFCsiSYiIiIichODaCIiIiIiNzGIJiIiIiJyE4NoIiIiIiI3cWAhkZ1v7k1Cdm6B3sUgIiIiA2MQTWSnd7NYvYtAREREBsfuHEREREREbmIQTURERETkJgbRRERERERuYhBNREREROQmBtFERERERG5iEE1ERERE5CYG0UREREREbmIQTURERETkJiGl1LsMbhNCnAVwVIdDVwdwTofjkmf4ffkPflf+g9+Vf+H35T/4XRlTQymlw1nY/DKI1osQIllKmah3Ocg1/L78B78r/8Hvyr/w+/If/K78D7tzEBERERG5iUE0EREREZGbGES7Z4beBSC38PvyH/yu/Ae/K//C78t/8LvyM+wTTURERETkJtZEExERERG5iUE0EREREZGbGES7SAgxWAhxQAiRKoSYqHd5goUQor4QYqUQYq8QYo8Q4nFleVUhxDIhRIryb4yyXAghpivf004hREerfY1Ttk8RQoyzWt5JCLFL+cx0IYTQ/n8aOIQQoUKIbUKIP5X38UKITcrv90chRISyPFJ5n6qsj7Pax/PK8gNCiEFWy3keqkQIUUUI8bMQYr8QYp8QohvPK+MSQjypXAN3CyF+EEJE8dwyBiHEV0KIDCHEbqtlPj+XnB2DNCSl5E8ZPwBCARwC0AhABIAdAFrpXa5g+AFQG0BH5XVFAAcBtALwNoCJyvKJAN5SXg8FsAiAANAVwCZleVUAh5V/Y5TXMcq6zcq2QvnsEL3/3/78A+ApAN8D+FN5PxfAaOX1ZwD+pbx+GMBnyuvRAH5UXrdSzrFIAPHKuRfK81D17+kbABOU1xEAqvC8MuYPgLoAjgAop7yfC+AenlvG+AHQC0BHALutlvn8XHJ2DP5o98OaaNckAUiVUh6WUuYDmANguM5lCgpSylNSyn+U19kA9sF0QxkOUxAA5d8RyuvhAGZLk40AqgghagMYBGCZlPKClPIigGUABivrKkkpN0rTlWi21b7ITUKIegCGAfhSeS8A9APws7KJ/Xdl/g5/BtBf2X44gDlSyjwp5REAqTCdgzwPVSKEqAzTjX8mAEgp86WUl8DzysjCAJQTQoQBiAZwCjy3DEFK+TeAC3aLtTiXnB2DNMIg2jV1ARy3ep+uLCMNKU2SCQA2AagppTylrDoNoKby2tl3VdrydAfLyTMfAHgOQLHyvhqAS1LKQuW99e/X8p0o6zOV7d39Dsl98QDOApildL35UghRHjyvDElKeQLAOwCOwRQ8ZwLYCp5bRqbFueTsGKQRBtHkF4QQFQD8AuAJKWWW9Trl6Zy5GnUmhLgBQIaUcqveZaEyhcHU/PyplDIBQA5MzcEWPK+MQ+nrOhymh586AMoDGKxrochlWpxLPF/1wSDaNScA1Ld6X09ZRhoQQoTDFEB/J6Wcpyw+ozRzQfk3Q1nu7LsqbXk9B8vJfd0B3CSESIOpObgfgA9haq4MU7ax/v1avhNlfWUA5+H+d0juSweQLqXcpLz/GaagmueVMQ0AcERKeVZKWQBgHkznG88t49LiXHJ2DNIIg2jXbAHQVBkJHQHTQI3fdS5TUFD68c0EsE9K+Z7Vqt8BmEcvjwMw32r53coI6K4AMpXmriUABgohYpRanYEAlijrsoQQXZVj3W21L3KDlPJ5KWU9KWUcTOfICinlnQBWArhV2cz+uzJ/h7cq20tl+Wglw0A8gKYwDazheagSKeVpAMeFEM2VRf0B7AXPK6M6BqCrECJa+X2avy+eW8alxbnk7BikFb1HNvrLD0wjag/CNIL5Rb3LEyw/AHrA1ES1E8B25WcoTP37lgNIAfAXgKrK9gLAJ8r3tAtAotW+7oVpIE0qgPFWyxMB7FY+8zGUmTz549X31gfXsnM0gulGnQrgJwCRyvIo5X2qsr6R1edfVL6PA7DK6sDzUNXvqAOAZOXc+g2mjAA8rwz6A+B1APuV3+m3MGXY4LllgB8AP8DUV70Aplae+7Q4l5wdgz/a/XDabyIiIiIiN7E7BxERERGRmxhEExERERG5iUE0EREREZGbGEQTEREREbmJQTQRERERkZsYRBMRERERuYlBNBERERGRm/4fQ/LxHXFZxkYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjpxCi3QVcAc"
      },
      "source": [
        "# Insert dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "m5GgFjRTK4-e",
        "outputId": "7765ea11-bb63-4284-8c4d-af751ac45f0b"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "\n",
        "audio_dataset_path='wav/dataset/akash/'\n",
        "metadata=pd.read_excel('wav/dataset/akash/akash_new.xlsx')\n",
        "metadata.head()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WhatsApp Audio 2021-06-09 at 7.03.07 PM.wav</td>\n",
              "      <td>akash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WhatsApp Audio 2021-06-09 at 7.03.07 PM (1).wav</td>\n",
              "      <td>akash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WhatsApp Audio 2021-06-09 at 7.03.06 PM.wav</td>\n",
              "      <td>akash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WhatsApp Audio 2021-06-09 at 7.03.06 PM (2).wav</td>\n",
              "      <td>akash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WhatsApp Audio 2021-06-09 at 7.03.06 PM (1).wav</td>\n",
              "      <td>akash</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         file_name  class\n",
              "0      WhatsApp Audio 2021-06-09 at 7.03.07 PM.wav  akash\n",
              "1  WhatsApp Audio 2021-06-09 at 7.03.07 PM (1).wav  akash\n",
              "2      WhatsApp Audio 2021-06-09 at 7.03.06 PM.wav  akash\n",
              "3  WhatsApp Audio 2021-06-09 at 7.03.06 PM (2).wav  akash\n",
              "4  WhatsApp Audio 2021-06-09 at 7.03.06 PM (1).wav  akash"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wKjd92nLKIv"
      },
      "source": [
        "def features_extractor(file):\n",
        "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "    \n",
        "    return mfccs_scaled_features"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rAbd67WVzKu"
      },
      "source": [
        "#### Extracting MFCC's For every audio file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s16JrIcNScn",
        "outputId": "55a249ba-8e50-459e-9bbf-6954f25d50e5"
      },
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "### Now we iterate through every audio file and extract features \n",
        "### using Mel-Frequency Cepstral Coefficients\n",
        "#extracted_features=[]\n",
        "for index_num,row in tqdm(metadata.iterrows()):\n",
        "    file_name = os.path.join(os.path.abspath(audio_dataset_path),str(row[\"file_name\"]))\n",
        "    final_class_labels=row[\"class\"]\n",
        "    data=features_extractor(file_name)\n",
        "    extracted_features.append([data,final_class_labels])\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800it [02:59,  4.46it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zcw1p0gSNdeN",
        "outputId": "bd1ca6e5-0f23-435c-c874-b7eb9ed96fc3"
      },
      "source": [
        "### converting extracted_features to Pandas dataframe\n",
        "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
        "extracted_features_df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-371.93112, 145.489, -22.60909, 18.450535, 40...</td>\n",
              "      <td>aman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-430.44672, 200.24297, -58.688416, 23.587633,...</td>\n",
              "      <td>aman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-447.62125, 208.67944, -55.273323, 18.741728,...</td>\n",
              "      <td>aman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-426.615, 201.91743, -52.755993, 23.815062, 4...</td>\n",
              "      <td>aman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-449.78067, 202.17969, -55.067146, 20.718473,...</td>\n",
              "      <td>aman</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             feature class\n",
              "0  [-371.93112, 145.489, -22.60909, 18.450535, 40...  aman\n",
              "1  [-430.44672, 200.24297, -58.688416, 23.587633,...  aman\n",
              "2  [-447.62125, 208.67944, -55.273323, 18.741728,...  aman\n",
              "3  [-426.615, 201.91743, -52.755993, 23.815062, 4...  aman\n",
              "4  [-449.78067, 202.17969, -55.067146, 20.718473,...  aman"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pGZpHN9UNlKa",
        "outputId": "36d08a2b-e0b8-4d43-f244-cf8341f7f476"
      },
      "source": [
        "extracted_features_df.tail()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1547</th>\n",
              "      <td>[-392.98712, 157.27275, -25.600758, 14.179449,...</td>\n",
              "      <td>akash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1548</th>\n",
              "      <td>[-382.30505, 161.24277, -35.295837, 7.4671283,...</td>\n",
              "      <td>akash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1549</th>\n",
              "      <td>[-411.27338, 153.2634, -21.0966, 13.288947, 40...</td>\n",
              "      <td>akash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1550</th>\n",
              "      <td>[-415.59647, 154.93677, -23.800282, 16.818874,...</td>\n",
              "      <td>akash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1551</th>\n",
              "      <td>[-406.82013, 154.63939, -25.195005, 15.650413,...</td>\n",
              "      <td>akash</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                feature  class\n",
              "1547  [-392.98712, 157.27275, -25.600758, 14.179449,...  akash\n",
              "1548  [-382.30505, 161.24277, -35.295837, 7.4671283,...  akash\n",
              "1549  [-411.27338, 153.2634, -21.0966, 13.288947, 40...  akash\n",
              "1550  [-415.59647, 154.93677, -23.800282, 16.818874,...  akash\n",
              "1551  [-406.82013, 154.63939, -25.195005, 15.650413,...  akash"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCOgrFirWBP0"
      },
      "source": [
        "### Split the dataset into independent and dependent dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olul6Px0NmUL"
      },
      "source": [
        "\n",
        "X=np.array(extracted_features_df['feature'].tolist())\n",
        "y=np.array(extracted_features_df['class'].tolist())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IRN6tp7N0MV"
      },
      "source": [
        "### Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HueY-NdYN9VL"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
        "    if train:\n",
        "        pred = clf.predict(X_train)\n",
        "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
        "        print(\"Train Result:\\n================================================\")\n",
        "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
        "        \n",
        "    elif train==False:\n",
        "        pred = clf.predict(X_test)\n",
        "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
        "        print(\"Test Result:\\n================================================\")        \n",
        "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
        "        print(\"_______________________________________________\")\n",
        "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGJ5GsF7WLT1"
      },
      "source": [
        "## Applying SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj9XNDYjPifr",
        "outputId": "c061d87d-6d58-43d9-86c9-f2a588897543"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "\n",
        "lr_clf = SGDClassifier(early_stopping=True,eta0=.0001,max_iter=2,random_state=22)\n",
        "lr_clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print_score(lr_clf, X_train, y_train, X_test, y_test, train=True)\n",
        "print_score(lr_clf, X_train, y_train, X_test, y_test, train=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Result:\n",
            "================================================\n",
            "Accuracy Score: 94.44%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                akash        aman  accuracy    macro avg  weighted avg\n",
            "precision    0.991424    0.902736    0.9444     0.947080      0.948616\n",
            "recall       0.900312    0.991653    0.9444     0.945982      0.944400\n",
            "f1-score     0.943673    0.945107    0.9444     0.944390      0.944366\n",
            "support    642.000000  599.000000    0.9444  1241.000000   1241.000000\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[578  64]\n",
            " [  5 594]]\n",
            "\n",
            "Test Result:\n",
            "================================================\n",
            "Accuracy Score: 95.18%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                akash        aman  accuracy   macro avg  weighted avg\n",
            "precision    1.000000    0.910714  0.951768    0.955357      0.956075\n",
            "recall       0.905063    1.000000  0.951768    0.952532      0.951768\n",
            "f1-score     0.950166    0.953271  0.951768    0.951719      0.951694\n",
            "support    158.000000  153.000000  0.951768  311.000000    311.000000\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[143  15]\n",
            " [  0 153]]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:557: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "truYbOmLWTJy"
      },
      "source": [
        "## Applying SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igIfo0J4PjPB",
        "outputId": "74c23f5b-02d1-4a85-befb-a898db13e463"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "svm_clf = SVC(kernel='rbf', gamma=0.1, C=1.0,random_state=32,)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "\n",
        "print_score(svm_clf, X_train, y_train, X_test, y_test, train=True)\n",
        "print_score(svm_clf, X_train, y_train, X_test, y_test, train=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Result:\n",
            "================================================\n",
            "Accuracy Score: 100.00%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "           akash   aman  accuracy  macro avg  weighted avg\n",
            "precision    1.0    1.0       1.0        1.0           1.0\n",
            "recall       1.0    1.0       1.0        1.0           1.0\n",
            "f1-score     1.0    1.0       1.0        1.0           1.0\n",
            "support    642.0  599.0       1.0     1241.0        1241.0\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[642   0]\n",
            " [  0 599]]\n",
            "\n",
            "Test Result:\n",
            "================================================\n",
            "Accuracy Score: 71.38%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                akash        aman  accuracy   macro avg  weighted avg\n",
            "precision    0.639676    1.000000  0.713826    0.819838      0.816942\n",
            "recall       1.000000    0.418301  0.713826    0.709150      0.713826\n",
            "f1-score     0.780247    0.589862  0.713826    0.685054      0.686585\n",
            "support    158.000000  153.000000  0.713826  311.000000    311.000000\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[158   0]\n",
            " [ 89  64]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh5JUuOKWeRr"
      },
      "source": [
        "## Applying RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH3aOn-dQ7Vw",
        "outputId": "c748f6b0-17dd-4d9f-907d-97a338165f4e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "rf_clf = RandomForestClassifier(n_estimators=1, random_state=42,max_depth=1)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "print_score(rf_clf, X_train, y_train, X_test, y_test, train=True)\n",
        "print_score(rf_clf, X_train, y_train, X_test, y_test, train=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Result:\n",
            "================================================\n",
            "Accuracy Score: 97.66%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                akash        aman  accuracy    macro avg  weighted avg\n",
            "precision    0.975194    0.978188  0.976632     0.976691      0.976639\n",
            "recall       0.979751    0.973289  0.976632     0.976520      0.976632\n",
            "f1-score     0.977467    0.975732  0.976632     0.976600      0.976630\n",
            "support    642.000000  599.000000  0.976632  1241.000000   1241.000000\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[629  13]\n",
            " [ 16 583]]\n",
            "\n",
            "Test Result:\n",
            "================================================\n",
            "Accuracy Score: 97.43%\n",
            "_______________________________________________\n",
            "CLASSIFICATION REPORT:\n",
            "                akash        aman  accuracy   macro avg  weighted avg\n",
            "precision    0.962963    0.986577  0.974277    0.974770      0.974580\n",
            "recall       0.987342    0.960784  0.974277    0.974063      0.974277\n",
            "f1-score     0.975000    0.973510  0.974277    0.974255      0.974267\n",
            "support    158.000000  153.000000  0.974277  311.000000    311.000000\n",
            "_______________________________________________\n",
            "Confusion Matrix: \n",
            " [[156   2]\n",
            " [  6 147]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ovRRSSJaRGK7",
        "outputId": "e9106413-1794-4e27-fb1c-d15763bab4b1"
      },
      "source": [
        "test_score = accuracy_score(y_test, lr_clf.predict(X_test)) * 100\n",
        "train_score = accuracy_score(y_train, lr_clf.predict(X_train)) * 100\n",
        "\n",
        "results_df = pd.DataFrame(data=[[\"SGDClassifier\", train_score, test_score]], \n",
        "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
        "results_df"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Training Accuracy %</th>\n",
              "      <th>Testing Accuracy %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SGDClassifier</td>\n",
              "      <td>94.439968</td>\n",
              "      <td>95.176849</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Model  Training Accuracy %  Testing Accuracy %\n",
              "0  SGDClassifier            94.439968           95.176849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "UC0WfVYiSH2h",
        "outputId": "689481f7-8909-4c22-e724-34b73b930bd4"
      },
      "source": [
        "test_score = accuracy_score(y_test, svm_clf.predict(X_test)) * 100\n",
        "train_score = accuracy_score(y_train, svm_clf.predict(X_train)) * 100\n",
        "\n",
        "results_df_2 = pd.DataFrame(data=[[\"Support Vector Machine\", train_score, test_score]], \n",
        "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)\n",
        "results_df"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Training Accuracy %</th>\n",
              "      <th>Testing Accuracy %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SGDClassifier</td>\n",
              "      <td>94.439968</td>\n",
              "      <td>95.176849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>71.382637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Model  Training Accuracy %  Testing Accuracy %\n",
              "0           SGDClassifier            94.439968           95.176849\n",
              "1  Support Vector Machine           100.000000           71.382637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "gw2_SUFdS4oS",
        "outputId": "a4f80a38-a553-4382-dbe5-42ae9db75dd3"
      },
      "source": [
        "test_score = accuracy_score(y_test, rf_clf.predict(X_test)) * 100\n",
        "train_score = accuracy_score(y_train, rf_clf.predict(X_train)) * 100\n",
        "\n",
        "results_df_2 = pd.DataFrame(data=[[\"Random Forest Classifier\", train_score, test_score]], \n",
        "                          columns=['Model', 'Training Accuracy %', 'Testing Accuracy %'])\n",
        "results_df = results_df.append(results_df_2, ignore_index=True)\n",
        "results_df"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Training Accuracy %</th>\n",
              "      <th>Testing Accuracy %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SGDClassifier</td>\n",
              "      <td>94.439968</td>\n",
              "      <td>95.176849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>71.382637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>97.663175</td>\n",
              "      <td>97.427653</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Model  Training Accuracy %  Testing Accuracy %\n",
              "0             SGDClassifier            94.439968           95.176849\n",
              "1    Support Vector Machine           100.000000           71.382637\n",
              "2  Random Forest Classifier            97.663175           97.427653"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YiFnfv7WtLe"
      },
      "source": [
        "## Applying Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozdPKgq7S-JO"
      },
      "source": [
        "\n",
        "\n",
        "### Label Encoding\n",
        "###y=np.array(pd.get_dummies(y))\n",
        "### Label Encoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder=LabelEncoder()\n",
        "y=to_categorical(labelencoder.fit_transform(y))\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjObxlKqTMm4"
      },
      "source": [
        "### Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBJNt8GLTPzY"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jyXBlwxTSLa"
      },
      "source": [
        "### No of classes\n",
        "num_labels=y.shape[1]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wik6jZ_NTWdc"
      },
      "source": [
        "model=Sequential()\n",
        "###first layer\n",
        "model.add(Dense(100,input_shape=(40,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "###second layer\n",
        "model.add(Dense(200))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "###third layer\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "###final layer\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogQaxU_hTZQy",
        "outputId": "e6de02a0-9be5-46da-90a7-3864996710d7"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 100)               4100      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               20100     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 202       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 44,602\n",
            "Trainable params: 44,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NebZT2rTcOO"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XA8-z8-rTrnD",
        "outputId": "e4ac3284-59c4-4cf1-d2eb-f6c3768071d9"
      },
      "source": [
        "## Trianing my model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime \n",
        "\n",
        "num_epochs =35\n",
        "num_batch_size = 32\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "start = datetime.now()\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "39/39 [==============================] - 1s 9ms/step - loss: 28.7150 - accuracy: 0.4875 - val_loss: 0.7871 - val_accuracy: 0.5563\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.78709, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 2/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 11.6600 - accuracy: 0.5101 - val_loss: 0.8476 - val_accuracy: 0.4662\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.78709\n",
            "Epoch 3/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 6.0775 - accuracy: 0.5665 - val_loss: 0.6558 - val_accuracy: 0.5659\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.78709 to 0.65581, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 4/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 4.2053 - accuracy: 0.5641 - val_loss: 0.7315 - val_accuracy: 0.4984\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.65581\n",
            "Epoch 5/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 3.0591 - accuracy: 0.5600 - val_loss: 0.7276 - val_accuracy: 0.4984\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.65581\n",
            "Epoch 6/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 2.2567 - accuracy: 0.5423 - val_loss: 0.6736 - val_accuracy: 0.5241\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.65581\n",
            "Epoch 7/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.6510 - accuracy: 0.5713 - val_loss: 0.6830 - val_accuracy: 0.5177\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.65581\n",
            "Epoch 8/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 1.1209 - accuracy: 0.6164 - val_loss: 0.6462 - val_accuracy: 0.9196\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.65581 to 0.64625, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 9/35\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 1.0354 - accuracy: 0.6221 - val_loss: 0.6309 - val_accuracy: 0.5627\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.64625 to 0.63092, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 10/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.9808 - accuracy: 0.6156 - val_loss: 0.6305 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.63092 to 0.63055, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 11/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.8523 - accuracy: 0.6463 - val_loss: 0.5959 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.63055 to 0.59592, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 12/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.7601 - accuracy: 0.6648 - val_loss: 0.5496 - val_accuracy: 0.9228\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.59592 to 0.54959, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 13/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.7789 - accuracy: 0.6769 - val_loss: 0.5274 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.54959 to 0.52737, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 14/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.6954 - accuracy: 0.7099 - val_loss: 0.4439 - val_accuracy: 0.9936\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.52737 to 0.44389, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 15/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.7244 - val_loss: 0.3921 - val_accuracy: 0.9293\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.44389 to 0.39214, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 16/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.5180 - accuracy: 0.7752 - val_loss: 0.2960 - val_accuracy: 0.9775\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.39214 to 0.29597, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 17/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7744 - val_loss: 0.2415 - val_accuracy: 0.9807\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.29597 to 0.24148, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 18/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.8050 - val_loss: 0.1948 - val_accuracy: 0.9614\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.24148 to 0.19480, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 19/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.3710 - accuracy: 0.8590 - val_loss: 0.1506 - val_accuracy: 0.9968\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.19480 to 0.15063, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 20/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.8719 - val_loss: 0.1087 - val_accuracy: 0.9968\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.15063 to 0.10865, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 21/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.8888 - val_loss: 0.0853 - val_accuracy: 0.9968\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.10865 to 0.08528, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 22/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2567 - accuracy: 0.8872 - val_loss: 0.0852 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.08528 to 0.08518, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 23/35\n",
            "39/39 [==============================] - 0s 5ms/step - loss: 0.2335 - accuracy: 0.9122 - val_loss: 0.0723 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.08518 to 0.07227, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 24/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.2155 - accuracy: 0.9226 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.07227\n",
            "Epoch 25/35\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1939 - accuracy: 0.9226 - val_loss: 0.0698 - val_accuracy: 0.9968\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.07227 to 0.06976, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 26/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1834 - accuracy: 0.9323 - val_loss: 0.0582 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.06976 to 0.05819, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 27/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1635 - accuracy: 0.9363 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.05819 to 0.04759, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 28/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9347 - val_loss: 0.0553 - val_accuracy: 0.9968\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.04759\n",
            "Epoch 29/35\n",
            "39/39 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9492 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.04759 to 0.04082, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 30/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1349 - accuracy: 0.9629 - val_loss: 0.0386 - val_accuracy: 0.9968\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.04082 to 0.03855, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 31/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9476 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.03855 to 0.02846, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 32/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1078 - accuracy: 0.9629 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.02846 to 0.02164, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 33/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9718 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.02164 to 0.01224, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 34/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.1147 - accuracy: 0.9621 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.01224 to 0.01055, saving model to saved_models/audio_classification.hdf5\n",
            "Epoch 35/35\n",
            "39/39 [==============================] - 0s 4ms/step - loss: 0.0560 - accuracy: 0.9799 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.01055 to 0.00507, saving model to saved_models/audio_classification.hdf5\n",
            "Training completed in time:  0:00:11.119129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEEciPUXTviT",
        "outputId": "ca079ec0-e5e1-4be7-d93b-025f9325b8db"
      },
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgUKGk4DUXz3",
        "outputId": "0442fa2f-e375-4444-9270-bc4838a43b26"
      },
      "source": [
        "filename=\"wav/dataset/aman/Recording (8)-converted.wav\"\n",
        "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
        "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "\n",
        "print(mfccs_scaled_features)\n",
        "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
        "print(mfccs_scaled_features)\n",
        "print(mfccs_scaled_features.shape)\n",
        "predicted_label=model.predict_classes(mfccs_scaled_features)\n",
        "print(predicted_label)\n",
        "prediction_class = labelencoder.inverse_transform(predicted_label) \n",
        "prediction_class"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-3.7193112e+02  1.4548900e+02 -2.2609091e+01  1.8450535e+01\n",
            "  4.0960831e+01 -1.3742833e+01 -4.1063385e+00  1.3415975e+01\n",
            " -1.1484894e+01 -9.9901972e+00  2.7550001e-02 -6.6313305e+00\n",
            "  1.4648305e+00  5.1530714e+00 -4.5525694e+00 -9.8004907e-01\n",
            "  4.4885907e-01 -6.1117506e+00 -2.1256275e+00 -7.2516806e-02\n",
            " -2.2938883e+00  3.0043283e+00  3.1290119e+00 -8.7787354e-01\n",
            "  2.6505778e+00  3.3047986e+00  1.1026218e+00  3.1278136e+00\n",
            "  6.6897023e-01 -2.5826888e+00  1.2943597e+00  2.6464984e+00\n",
            "  5.1432317e-01  1.3826212e+00  1.0832032e+00 -2.0555533e-01\n",
            "  7.5960594e-01  3.9840186e-01 -7.1845204e-01 -4.8347920e-01]\n",
            "[[-3.7193112e+02  1.4548900e+02 -2.2609091e+01  1.8450535e+01\n",
            "   4.0960831e+01 -1.3742833e+01 -4.1063385e+00  1.3415975e+01\n",
            "  -1.1484894e+01 -9.9901972e+00  2.7550001e-02 -6.6313305e+00\n",
            "   1.4648305e+00  5.1530714e+00 -4.5525694e+00 -9.8004907e-01\n",
            "   4.4885907e-01 -6.1117506e+00 -2.1256275e+00 -7.2516806e-02\n",
            "  -2.2938883e+00  3.0043283e+00  3.1290119e+00 -8.7787354e-01\n",
            "   2.6505778e+00  3.3047986e+00  1.1026218e+00  3.1278136e+00\n",
            "   6.6897023e-01 -2.5826888e+00  1.2943597e+00  2.6464984e+00\n",
            "   5.1432317e-01  1.3826212e+00  1.0832032e+00 -2.0555533e-01\n",
            "   7.5960594e-01  3.9840186e-01 -7.1845204e-01 -4.8347920e-01]]\n",
            "(1, 40)\n",
            "[1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['aman'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY5eyWVIUf-g"
      },
      "source": [
        "import speech_recognition as sr\n",
        "filename = 'wav/Recording (2)conv.wav'\n",
        "r = sr.Recognizer()\n",
        "# open the file\n",
        "with sr.AudioFile(filename) as source:\n",
        "    # listen for the data (load audio to memory)\n",
        "    audio_data = r.record(source)\n",
        "    # recognize (convert from speech to text)\n",
        "    text = r.recognize_google(audio_data)\n",
        "    print(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eIGufNGXSBM"
      },
      "source": [
        "### Output- please open the door"
      ]
    }
  ]
}